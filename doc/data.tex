% DATA.TEX
%
% The documentation in this file is part of PyXPlot
% <http://www.pyxplot.org.uk>
%
% Copyright (C) 2006-2010 Dominic Ford <coders@pyxplot.org.uk>
%               2009-2010 Ross Church
%
% $Id$
%
% PyXPlot is free software; you can redistribute it and/or modify it under the
% terms of the GNU General Public License as published by the Free Software
% Foundation; either version 2 of the License, or (at your option) any later
% version.
%
% You should have received a copy of the GNU General Public License along with
% PyXPlot; if not, write to the Free Software Foundation, Inc., 51 Franklin
% Street, Fifth Floor, Boston, MA  02110-1301, USA

% ----------------------------------------------------------------------------

% LaTeX source for the PyXPlot Users' Guide

\chapter{Working with Data}
\label{ch:numerics}

In this chapter, we describe more sophisticated ways of dealing with data files
and outline the facilities provided for data processing within PyXPlot.

\section{Input Filters}
\label{sec:filters}

By default, PyXPlot expects \datafile s to be in a simple plaintext format
which is described in Section~\ref{sec:plot_datafiles}. Input filters provide a
mechanism by which \datafile s in arbitrary formats can be read into PyXPlot.
For each filter, a filename wildcard is supplied, and the filter is then applied to
all \datafile s whose filenames match this wildcard. For example, by default
PyXPlot has five input filters installed, as the {\tt show filters} command
reveals:

\begin{verbatim}
set filter "*.fits"   "/usr/local/bin/pyxplot_fitshelper"
set filter "*.gz"     "/bin/gunzip -c"
set filter "*.log"    "/usr/local/bin/pyxplot_timehelper"
set filter "ftp://*"  "/usr/bin/wget -O -"
set filter "http://*" "/usr/bin/wget -O -"
\end{verbatim}

Each filter takes the form of a program which is launched by PyXPlot, passed
the content the datafile on {\tt stdin}, and expected to output data to PyXPlot
in plaintext format using {\tt stdout}. Any errors returned to {\tt stderr} are
passed to the user.

The above set of filters allow PyXPlot to read in data from gzipped plaintext
data files, data tables in FITS format, and from data files available over the
web. Finally, a filter is provided for converting textual dates in log files
into numbers representing days, months and years. To add to this list of
filters, it is necessary to write a short program or shell script, and the
filters provided for {\tt .log} and {.fits} files may provide a useful model.

\section{Reading Data from a Pipe}

PyXPlot usually reads data from a file, but it possible to read data via a pipe
from standard input.  To do this, one uses the magic filename {\tt -}:

\begin{verbatim}
plot '-' with lines
\end{verbatim}

This makes it possible to call PyXPlot from within a program and to pass it
some data to plot without ever storing the data on disk.  However, we would
generally discourage you from doing this. Unless you really {\it need} to do
otherwise, we would recommend that you write your data to a file on disk, and
then to plot it from inside PyXPlot in a separate step.  Whilst it is often
tempting to write programs which both perform calculations and plot the results
immediately, this can be a dangerous path. A few months after the event, when
the need arises to replot the same data in a different form or in a different
style, remembering how to use a sizeable program can prove tricky -- especially
if the person struggling to do so is not you! But a simple \datafile\ is quite
straightforward to plot time and again.

\section{Including Data within Command Scripts}

It is also possible to embed data directly within PyXPlot scripts, which may be
useful when a small number of markers are wanted at particular pre-defined
positions on a graph, or when it is desirable to roll a PyXPlot script and data
into a single file for easy storage or transmission. To do this, one uses the
magic filename {\tt --} and terminates the data with the string {\tt END}:

\begin{verbatim}
plot '--' with lines
0 0
1 1
2 0
3 1
END
print "More PyXPlot commands can be placed after END"
\end{verbatim}

\section{Tabulating Functions and Slicing Data Files}

PyXPlot's \indcmdt{tabulate} can be used to produce a text file containing the
values of a function at a set of points.  For example, the following would
produce a data file called {\tt sine.dat} containing a list of values of the
sine function:

\begin{verbatim}
set output 'sine.dat'
tabulate [-pi:pi] sin(x)
\end{verbatim}

\noindent Multiple functions may be tabulated into the same file, either by
using the \indmodt{using} modifier:

\begin{verbatim}
tabulate [0:2*pi] sin(x):cos(x):tan(x) u 1:2:3:4
\end{verbatim}

\noindent or by placing them in a comma-separated list, as in the {\tt plot}
command:

\begin{verbatim}
tabulate [0:2*pi] sin(x), cos(x), tan(x)
\end{verbatim}

The {\tt samples} setting can be used to control the number of points that are
inserted into the data file:\indcmd{set samples}

\begin{verbatim}
set samples 200
\end{verbatim}

\noindent If the $x$-axis is set to be logarithmic then the points at which the
functions are evaluated are spaced logarithmically.

The {\tt tabulate} command can also be used to select portions of data files
for output into a new file.  For example, the following would write out the
third, sixth and ninth columns of the datafile {\tt input.dat}, but only when
the arcsine of the value in the fourth column is positive:

\begin{verbatim}
set output 'filtered.dat'
tabulate 'input.dat' u 3:6:9 select (asin($4)>0)
\end{verbatim}

\noindent The \indmodt{select}, \indmodt{using} and \indmodt{every} modifiers
operate in the same manner as with the {\tt plot} command.

The format used in each column of the output file is chosen automatically with
integers and small numbers treated intelligently to produce output which
preserves accuracy, but is also easily human-readable. If desired, however, a
format statement may be specified using the {\tt with format} specifier. The
syntax for this is similar to that expected by the Python string substitution
operator ({\tt \%})\index{\% operator@{\tt \%} operator}\index{string
operators!substitution}\footnote{Note that this operator can also be used
within PyXPlot; see Section~\ref{sec:string_subs_op} for details.}.  For example,
to tabulate the values of $x^2$ to very many significant figures one could use:

\begin{verbatim}
tabulate x**2 with format "%27.20e"
\end{verbatim}

If there are not enough columns present in the supplied format statement it
will be repeated in a cyclic fashion; e.g. in the example above the single
supplied format is used for both columns.

\section{Function Fitting}
\label{sec:fit_command}

The \indcmdt{fit} allows the user to fit arbitrary functional forms to
\datapoint s read from files.  This may be used to produce best-fit
lines\index{best fit lines}\footnote{Another way of producing best-fit lines is
to use a cubic spline; more details are given in
Section~\ref{sec:spline_command}}, or may be used to determine the gradient and
other mathematical properties of datasets, by looking at the parameters used to
make the functional form fit the data.

The following simple example fits a straight line to data in
a file called {\tt data.dat}:

\begin{verbatim}
f(x) = a*x+b
fit f() 'data.dat' index 1 using 2:3 via a,b
\end{verbatim}

\noindent The first line specifies the functional form which is to be used.
The coefficients within this function which are to be varied during the fitting
process are listed after the keyword \indkeyt{via} in the {\tt fit} command.
The modifiers \indmodt{index}, \indmodt{every}, \indmodt{select} and
\indmodt{using} have the same meanings as in the {\tt plot} command.  For example,
given the following \datafile\ which contains a sampled square wave, entitled
{\tt square.dat}:

\begin{verbatim}
    0.314159          1
    0.942478          1
    1.570796          1
    2.199115          1
    2.827433          1
    3.455752         -1
    4.084070         -1
    4.712389         -1
    5.340708         -1
    5.969026         -1
\end{verbatim}

\noindent the following script fits a truncated Fourier series to it:

\begin{verbatim}
f(x) = a1*sin(x) + a3*sin(3*x) + a5*sin(5*x)
fit f() 'square.dat' via a1, a3, a5
set xlabel '$x$' ; set ylabel '$y$'
plot 'square.dat' title 'data' with points pointsize 2, \
     f(x) title 'Fitted function' with lines
\end{verbatim}

\begin{center}
\includegraphics[width=8cm]{examples/eps/ex_fitting.eps}
\end{center}

As the \indcmdt{fit} works, it displays statistics including the best-fit
values of each of the fitting parameters, the uncertainties in each of them,
and the covariance matrix. These can be useful for analysing the security of
the fit achieved, but calculating the uncertainties in the best-fit parameters
and the covariance matrix can be time consuming, especially when many
parameters are being fitted simultaneously. The optional word {\tt
withouterrors} can be included immediately before the filename of the \datafile
to be fitted to substantially speed up cases where this information is not
required.

A few points are worth noting:

\begin{itemize}
\item When fitting a function of $n$ variables, at least $n+1$ columns (or
rows -- see Section~\ref{sec:horizontal_datafiles}) must be specified after the
{\tt using} modifier. By default, the first $n+1$ columns are used. These
correspond to the values of each of the $n$ inputs to the function, plus
finally the value which the output from the function is aiming to match.
\item If an additional column is specified, then this is taken to contain the
standard error in the value that the output from the function is aiming to
match, and can be used to weight the \datapoint s which are input into the
{\tt fit} command.
\item By default, the starting values for each of the fitting parameters is
$1.0$. However, if the variables to be used in the fitting process are already
set before the {\tt fit} command is called, these initial values are used
instead. For example, the following would use the initial values
$\{a=100,b=50\}$:
\begin{verbatim}
f(x) = a*x+b
a = 100
b = 50
fit f() 'data.dat' index 1 using 2:3 via a,b
\end{verbatim}

\item As with all numerical fitting procedures, the {\tt fit} command comes
with caveats. It uses a generic fitting algorithm, and may not work well with
poorly behaved or ill-constrained problems. It works best when all of the
values it is attempting to fit are of order unity. For example, in a problem
where $a$ was of order $10^{10}$, the following might fail:
\begin{verbatim}
f(x) = a*x
fit f() 'data.dat' via a
\end{verbatim}
However, better results might be achieved if $a$ were artificially made of
order unity, as in the following script:
\begin{verbatim}
f(x) = 1e10*a*x
fit f() 'data.dat' via a
\end{verbatim}

\item A series of ranges may be specified after the {\tt fit} command, using
the same syntax as in the {\tt plot} command, as described in
Section~\ref{sec:plot_ranges}. If ranges are specified then only \datapoint s
falling within these ranges are used in the fitting process; the ranges refer
to each of the $n$ variables of the fitted function in order:
\begin{verbatim}
fit [0:10] f() 'data.dat' via a
\end{verbatim}

\item For those interested in the mathematical details, the workings of the
{\tt fit} command is discussed in more detail in Appendix~\ref{ch:fit_maths}.

\end{itemize}

\section{Datafile Interpolation}
\label{sec:spline_command}
\index{best fit lines}

The \indcmdt{interpolate} can be used to generate a special function within
PyXPlot which interpolates a set of \datapoint s supplied from a data file.
Various different types of interpolation are supported: linear interpolation,
power-law interpolation\footnote{Power-law interpolation is equivalent to
linear interpolation in log-log space.}, polynomial interpolation and
cubic-spline interpolation. The use of polynomial interpolation with large
datasets is strongly discouraged, as polynomial fits tend to show severe
oscillations between \datapoint s.

The \indcmdt{interpolate} has similar syntax to the \indcmdt{fit}:

\begin{verbatim}
interpolate ( linear | loglinear | polynomial | spline )
            [<range specification>] <function name>() '<filename>' 
            [index <index specification>]
            [every <every specification>]
            [using <using specification>]
\end{verbatim}

A very common application of the \indcmdt{interpolate} is to perform arithmetic
functions such as addition or subtraction on datasets which are not sampled at
the same abscissa values. The following example would plot the difference
between two such datasets:

\begin{verbatim}
interpolate linear f() 'data1.dat'
interpolate linear g() 'data2.dat'
plot [min:max] f(x)-g(x)
\end{verbatim}

\noindent Note that it is advisable to supply a range to the {\tt plot} command
in this example: because the two datasets have been turned into continuous
functions, the {\tt plot} command has to guess a range to plot them over unless
one is explicitly supplied.

The functions have not, however, lost the range of the original data: because
it is generally very inadvisable to extrapolate interpolated function fits
beyond the limits of the \datapoint s used to constain the fit, PyXPlot returns
an error or NaN if this is attempted.

Smoothed splines can also be produced:

\begin{verbatim}
interpolate spline f() 'data1.dat' smooth 1.0
\end{verbatim}

\noindent where the value $1.0$ determines the degree of smoothing to apply;
the higher the value, the more smoothing is applied. The default behaviour is
not to smooth at all -- equivalent to {\tt smooth 0.0} -- and a value of $1.0$
corresponds to a moderate degree of smoothing.

The \indcmdt{spline} command is an alias for {\tt interpolate spline}; the
following two statements are equivalent:

\begin{verbatim}
spline f() 'data1.dat'
interpolate spline f() 'data1.dat'
\end{verbatim}

\example{ex:interpolation}{An example}{
In this example,.
}

\section{Fourier Transforms}

The {\tt fft} and {\tt ifft} commands\indcmd{fft}\indcmd{ifft} take Fourier
transforms and inverse Fourier transforms respectively of data supplied either
from a file or from a function. In each case, a regular grid of ordinate values
must be specified on which to take the discrete Fourier transform, which can
extend over an arbitrary number of dimensions. The following example
demonstrates the syntax of these commands as applied to a function:

\begin{verbatim}
step(x,y) = tophat(x,0.2) * tophat(y,0.4)
fft  [  0: 1:0.01][  0: 1:0.01] f() of step()
ifft [-50:49:1   ][-50:49:1   ] g() of f()
\end{verbatim}

\noindent In the {\tt fft} command, $N_x=100$~equally-spaced samples of the
function {\tt step}$(x,y)$ are taken between limits of $x_\mathrm{min}=0$ and
$x_\mathrm{max}=1$ for each of $N_y=100$~equally-spaced values of $y$ on an
identical raster, giving a total of $10^4$ samples. These are converted into a
rectangular grid of $10^4$~samples of the Fourier transform {\tt
f}$(\omega_x,\omega_y)$ at

\begin{eqnarray}
\omega_x = \frac{j}{\Delta x} & \textrm{for} & -\frac{N_x}{2}\leq j <\frac{N_x}{2} , \nonumber \\
\omega_y = \frac{k}{\Delta y} & \textrm{for} & -\frac{N_y}{2}\leq k <\frac{N_y}{2} . \nonumber
\end{eqnarray}

\noindent where $\Delta x=x_\mathrm{max}-x_\mathrm{min}$ and $\Delta y$ is
analogously defined. These samples are interpolated stepwise, such that an
evaluation of the function {\tt f}$(\omega_x,\omega_y)$ for general inputs
yields the nearest sample, or zero outside the rectangular grid where samples
are available. The Fourier transforms of even real functions are, in general,
complex, and their evaluation when complex arithmetic is not enabled (see
Section~\ref{sec:complex_numbers}) is likely to fail. For this reason, a
warning is issued if complex arithmetic is disabled when a Fourier transform
function is evaluated.

In the example above, we go on to convert this set of samples back into the
function we started with by instructing the \indcmdt{ifft} to take
$N_x=100$~equally-spaced samples along the $\omega_x$-axis between
$\omega_{x,\mathrm{min}}=-{N_x}/{2\Delta x}$ and
$\omega_{x,\mathrm{max}}=(N_x-1)/{2\Delta x}$, with similar sampling along the
$\omega_y$-axis.

Taking the simpler example of a one-dimensional Fourier transform for clarity,
as might be calculated by the instructions
\begin{verbatim}
step(x) = tophat(x,0.2)
fft  [  0: 1:0.01] f() of step()
\end{verbatim}
the {\tt fft} and {\tt ifft} commands\indcmd{fft}\indcmd{ifft} compute,
respectively, discrete sets of samples $F_m$ and $I_n$ of the functions
$F(\omega_x)$ and $I(x)$, which are given by
\begin{displaymath}
F_j = \sum_{m=0}^{N-1} I_m e^{-2\pi ijm/N} \,\delta x,\;\textrm{for}\; -\frac{N}{2}\leq m <\frac{N}{2} ,
\end{displaymath}
\noindent and
\begin{displaymath}
I_j = \sum_{m=0}^{N-1} F_m e^{ 2\pi ijm/N} \,\delta \omega_x,\;\textrm{for}\; -\frac{N}{2}\leq m <\frac{N}{2} ,
\end{displaymath}
\noindent where:
\begin{tabular}{rcp{9cm}}
$I(x)$        & = & Function being Fourier transformed. \\
$F(\omega_x)$ & = & Fourier transform of $I()$. \\
$N$           & = & The number of ordinate values sampled along the $x$ axis. \\
$\delta x$    & = & Spacing of ordinate values sampled along the $x$ axis. \\
$\delta \omega_x$ & = & Spacing of ordinate values sampled along the $\omega_x$ axis. \\
$i$           & = & $\sqrt{-1}$. \\
\end{tabular}
\vspace{2mm}

It may be shown in the limit that $\delta x$ becomes small -- i.e.\ when the
number of samples taken becomes very large -- that these sums approximate the
integrals
\begin{equation}
F(\omega_x) = \int I(x) e^{-2\pi ix\omega_x} \,\mathrm{d}x ,
\end{equation}
\noindent and
\begin{equation}
I(x) = \int F(\omega_x) e^{ 2\pi ix\omega_x} \,\mathrm{d}\omega_x .
\end{equation}

Fourier transforms may also be taken of data stored in \datafile s using syntax
of the form
\begin{verbatim}
fft [-10:10:0.1] f() of 'datafile.dat'
\end{verbatim}

\noindent In such cases, the data read from the \datafile for an
$N$-dimensional FFT must be arranged in $N+1$ columns\footnote{The {\tt using},
{\tt every}, {\tt index} and {\tt select} modifiers can be used to arrange it
into this form.}, with the first $N$ containing the ordinate values for each of
the $N$ dimensions, and the final column containing the data to be Fourier
transformed. The ordinate values must strictly match those in the raster
specified in the {\tt fft} or {\tt ifft} command, and must be arranged strictly
in row-major order.

\example{ex:fourier}{The Fourier transform of a top-hat function}{
It is straightforward to show that the Fourier transform of a top-hat function
of unit width is the function $\sinc(x)=\sin(\pi x)/\pi x$. If
\begin{displaymath}
f(x)=\left\{\begin{array}{l}1\;|x|\leq\nicefrac{1}{2}\\0\;|x|>\nicefrac{1}{2}\end{array}\right. ,
\end{displaymath}
then the Fourier transform $F(\omega)$ of $f(x)$ is
\begin{eqnarray*}
F(\omega) & = & \int_0^\infty f(x) \exp \left(-2\pi ix\omega\right) \,\mathrm{d}x
            =   \int_{-\nicefrac{1}{2}}^{\nicefrac{1}{2}} \exp\left(-2\pi ix\omega\right) \,\mathrm{d}x
\\        & = & \frac{1}{2\pi\omega}\left[ \exp\left(\pi i\omega\right) - \exp\left(-\pi i\omega\right) \right]
            = \frac{\sin(\pi\omega)}{\pi\omega}
            = \sinc(\omega).
\end{eqnarray*}
\nlnp
In this example, we demonstrate this by taking the Fourier transform of such a
step function, and comparing the result against the function {\tt sinc(x)}
which is pre-defined within PyXPlot:
\nlscf
\noindent{\tt set numerics complex}\newline
\noindent{\tt step(x) = tophat(x,0.5)}\newline
\noindent{\tt fft [-1:1:0.01] f() of step()}\newline
\noindent{\tt plot [-10:10] Re(f(x)), sinc(x)}
\nlscf
Note that the function {\tt Re(x)} is needed in the {\tt plot} statement here,
since although the Fourier transform of a symmetric function is in theory real,
in practice any numerical Fourier transform will yield a small imaginary
component at the level of the accuracy of the numerical method used. Although
the calculated numerical Fourier transform is defined throughout the range
$-50\leq x<50$, discretised with steps of size $\Updelta x=0.5$, we only plot
the central region in order to clearly show the stepping of the function:
\nlscf
\begin{center}
\includegraphics{examples/eps/ex_fft.eps}
\end{center}
\nlscf
In the following steps, we take the square of the function $\sinc(x)$ just
calculated, and then plot the numerical inverse Fourier transform of the
result:
\nlscf
\noindent{\tt g(x) = f(x)**2}\newline
\noindent{\tt ifft [-50:49.5:0.5] h(x) of g(x)}\newline
\noindent{\tt plot [-2:2] Re(h(x))}
\nlscf
\begin{center}
\includegraphics{examples/eps/ex_fft2.eps}
\end{center}
\nlscf
As can be seen, the result is a triangle function. This is the result which
would be expected from the convolution theorem, which states that when the
Fourier transforms of two functions are multiplied together and then inverse
transformed, the result is the convolution of the two original functions. The
convolution of a top-hat function with itself is, indeed, a triangle function.
}

\subsection{Window Functions}
\index{window functions}

A range of commonly-used window functions may automatically be applied to data
as it is read into the {\tt fft} and {\tt ifft} commands; these are listed
together with their algebraic forms in Table~\ref{tab:windowfuncs} and shown in
Figure~\ref{fig:windowfuncs}. In each case, the window functions are given for
sample number $n$, which ranges between $0$ and $N_x$. The window functions may
be invoked using the following syntax:

\begin{verbatim}
fft [...] out() of in() window <window_name>
\end{verbatim}

\noindent Where multi-dimensional FFTs are performed, window functions are
applied to each dimension in turn.  Other arbitrary window functions may be
implemented by pre-multiplying data before entry to the {\tt fft} and {\tt
ifft} commands.

\begin{table}
\newlength{\wfgap}
\setlength{\wfgap}{3mm}
\begin{tabular}{ll}
{\bf Window Name} & {\bf Algebraic Definition} \vspace{\wfgap}\\
Bartlett     & $\displaystyle w(n) = \left( \frac{2}{N_x-1} \right) \left( \frac{N_x-1}{2} - \left| n - \frac{N_x-1}{2} \right| \right)$ \vspace{\wfgap}\\
BartlettHann & $\displaystyle w(n) = a_0 - a_1\left|\frac{n}{N_x-1}-\frac{1}{2}\right| - a_2\cos\left(\frac{2\pi n}{N_x-1}\right),\;\textrm{for}$ \vspace{2mm}\\
             & $a_0=0.62,\; a_1=0.48,\; a_2=0.38.$ \vspace{\wfgap}\\
Cosine       & $\displaystyle w(n) = \cos\left(\frac{\pi n}{N_x-1} - \frac{\pi}{2} \right)$ \vspace{\wfgap}\\
Gauss        & $\displaystyle w(n) = \exp \left\{ -\frac{1}{2}\left[ \frac{n-(N_x-1)/2}{\sigma(N_x-1)/2} \right]^2 \right\},\;\textrm{for}\;\sigma=0.5$ \vspace{\wfgap}\\
Hamming      & $\displaystyle w(n) = 0.54 - 0.46\cos\left(\frac{2\pi n}{N_x-1}\right)$ \vspace{\wfgap}\\
Hann         & $\displaystyle w(n) = 0.5 \left[ 1 - \cos\left(\frac{2\pi n}{N_x-1}\right) \right]$ \vspace{\wfgap}\\
Lanczos      & $\displaystyle w(n) = \mathrm{sinc}\left( \frac{2n}{N_x-1} - 1 \right)$ \vspace{\wfgap}\\
Rectangular  & $\displaystyle w(n) = 1$ \vspace{\wfgap}\\
Triangular   & $\displaystyle w(n) = \left( \frac{2}{N_x} \right) \left( \frac{N_x}{2} - \left| n - \frac{N_x-1}{2} \right| \right)$ \vspace{\wfgap}\\
\end{tabular}
\caption{Window functions available in the {\tt fft} and {\tt ifft} commands.}
\label{tab:windowfuncs}
\end{table}

\begin{figure}
\begin{center}
\includegraphics{examples/eps/ex_windowfuncs.eps}
\end{center}
\caption{Window functions available in the {\tt fft} and {\tt ifft} commands.}
\label{fig:windowfuncs}
\end{figure}

\section{Histograms}

The \indcmdt{histogram} takes data from a file and bins it, producing a
function that represents the frequency distribution of the supplied data.  A
histogram is defined as a function consisting of discrete intervals, the area
under each of which is equal to the number of points binned in that interval.
For example:

\begin{verbatim}
histogram f() 'input.dat'
\end{verbatim}

\noindent bins the points in the first column of the file {\tt input.dat}
into bins of unit width and produces a function $f()$, the value of which at any
given point is equal to the number of items in the bin at that point.

Modifiers can be supplied to the \indcmdt{histogram} command to control the bins
that it uses.  The \indmodt{binwidth} modifier sets the width of the bins used
and the \indmodt{binorigin} modifier their origin.  For example:

\begin{verbatim}
histogram wabbitcount() 'rabbits.dat' binorigin 0.5 binwidth 2
\end{verbatim}

\noindent bins the rabbit data into bins between $0.5$ and $2.5$, $2.5$ and
$4.5$, etc.  Alternatively the \indmodt{bins} modifier allows an arbitrary set
of bins to be specified. For example the command:

\begin{verbatim}
histogram g() 'input.dat' bins (1, 2, 4)
\end{verbatim}

\noindent would bin the points in the first column of the file {\tt input.dat}
into two bins, $x=1\to 2$ and $x=2\to 4$.

A range can be supplied immediately following the command, using the same
syntax as in the {\tt plot} and {\tt fit} commands; only points that fall in
that range will be binned.  In the same way as for the {\tt plot} command,
the \indmodt{index}, \indmodt{every}, \indmodt{using} and \indmodt{select}
modifiers can also be used to bin different portions of a datafile.

Note that, although a histogram is similar to a bar chart, they are subtly
different.  A bar chart has the {\it height} of the bar equal to the number of
points that it represents; for a histogram the {\it area} of the bar is equal to
the number of points.  To produce a bar chart use the histogram
command and then multiply by the bin width when plotting.

If the function produced by the histogram command is plotted using the
\indpst{boxes} plot style, box boundaries will be drawn to coincide with the
bins into which the data were sorted.

\section{Random Data Generation}

PyXPlot has a range of mathematical functions which draw random samples for a
variety of probability distibutions. These are:

\vspace{2mm}
\noindent
\begin{tabular}{lp{7.5cm}}
{\tt random()} & returns a random real number between 0 and~1. \\
{\tt random\_binomial($p,n$)} & returns a random sample from a binomial distribution with $n$ independent trials and a success probability $p$. \\
{\tt random\_chisq($\mu$)} & returns a random sample from a $\chi$-squared distribution with $\mu$ degrees of freedom. \\
{\tt random\_gaussian($\sigma$)} & returns a random sample from a Gaussian (normal) distribution of standard deviation $\sigma$ and centred upon zero. \\
{\tt random\_lognormal($\zeta,\sigma$)} & returns a random sample from the log normal distribution centred on $\zeta$, and of width $\sigma$. \\
{\tt random\_poisson($n$)} & returns a random integer from a Poisson distribution with mean $n$. \\
\end{tabular}
\vspace{2mm}

\noindent The functions all rely upon a common underlying random-number
generator, whose seed may be set using the \indcmdt{set seed}, followed by any
integer.

\example{ex:random}{Using random numbers to estimate the value of $\pi$.}{
PyXPlot's functions for generating random numbers are most commonly used for
adding noise to artificially-generated data. In this example, however, we use
them to implement a rather inefficient algorithm for estimating the value of
the mathematical constant $\pi$.  The algorithm works by spreading
randomly-placed samples in the square $\left\{ -1<x<1;\; -1<y<1\right\}$. The
number of these which lie within the circle of unit radius about the origin are
then counted. Since the square has an area of $4\,\mathrm{unit}^2$ and the
circle has an area of $\pi\,\mathrm{unit}^2$, the fraction of the points which
lie within the unit circle equal the ratio of these two areas: $\pi/4$.
\nlnp
The following script performs this calculation using $N=5000$~randomly placed
samples. First, the positions of the random samples are generated using the
{\tt random()} function, and output to a file called {\tt random.dat} using the
{\tt tabulate} command. Then, the {\tt foreach datum} command -- which will be
introduced in Section~\ref{sec:foreach_datum} -- is used to loop over these,
counting how many lie within the unit circle.
\nlscf
\noindent {\tt Nsamples = 5000 }\newline
\noindent {\tt }\newline
\noindent {\tt set samp Nsamples }\newline
\noindent {\tt set output "random.dat" }\newline
\noindent {\tt tabulate 1-2*random():1-2*random() using 0:2:3 }\newline
\noindent {\tt }\newline
\noindent {\tt n=0 }\newline
\noindent {\tt foreach datum i,j in 'random.dat' using 2:3 \{ }\newline
\noindent {\tt \phantom{xx}n = n + (hypot(i,j)<1) }\newline
\noindent {\tt \} }\newline
\noindent {\tt }\newline
\noindent {\tt print "pi=\%s"\%(n / Nsamples * 4) }\newline
\nlfcf
On the author's machine, this script returns a value of $3.1352$ when executed
using the random samples which are returned immediately after starting PyXPlot.
This method of estimating $\pi$ is well modelled as a Poisson process, and the
uncertainty in this result can be estimated from the Poisson distribution to be
$1/\sqrt{N}$. In this case, the uncertainty is $0.01$, in close agreement with
the deviation of the returned value of $3.1352$ from more accurate measures of
$\pi$.
\nlnp
With a little modification, this script can be adapted to produce a diagram of the
datapoints used in its calculation. Below is a modified version of the second
half of the script, which loops over the \datapoint s previously stored in the
\datafile\ {\tt random.dat} which uses PyXPlot's vector graphics commands,
which will be introduced in Chapter~\ref{ch:vector_graphics}, to produce such a
diagram:

\nlscf
\noindent {\tt set multiplot ; set nodisplay}\newline
\noindent {\tt \# Draw a unit circle and a unit square}\newline
\noindent {\tt box from -width/2,-width/2 to width/2,width/2}\newline
\noindent {\tt circle at 0,0 radius width/2 with lt 2}\newline
\noindent {\tt }\newline
\noindent {\tt \# Now plot the positions of the random data points}\newline
\noindent {\tt n=0}\newline
\noindent {\tt foreach datum i,j in 'random.dat' using 2:3}\newline
\noindent {\tt \phantom{x}\{}\newline
\noindent {\tt \phantom{xx}point at width/2*i , width/2*j with ps 0.1}\newline
\noindent {\tt \phantom{xx}n = n + (hypot(i,j)<1)}\newline
\noindent {\tt \phantom{x}\}}\newline
\noindent {\tt set display ; refresh}\newline
\noindent {\tt }\newline
\noindent {\tt print "pi=\%s"\%(n / Nsamples * 4) }\newline
\nlscf
The graphical output from this script is shown below. The number of datapoints
has been reduced to {\tt Nsamples}$=500$ for clarity:
\nlscf
\begin{center}
\includegraphics{examples/eps/ex_pi_estimation.eps}
\end{center}
}

